{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5066f6a3-1fd4-40fb-a75c-19aafe0d2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91a10cc-e783-4c3d-8994-fdbceb86f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9abe7183-52fa-4089-a985-c373d31fe088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc5af9d-fbdb-4b9d-99c6-d7604d4a6373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e71144-e007-4d85-b8a5-ead41a71c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok biolerplate done, now we get to the action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c6b6cb3-3207-495b-935c-5575fc287529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item() # Checks if all elements are the same. ex is a boolean\n",
    "  app = torch.allclose(dt, t.grad) # Approximately equal due to floating point arithmetic\n",
    "  maxdiff = (dt - t.grad).abs().max().item() #Highest difference\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2043cce-1745-4347-b928-413f44ba4d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e55141ca-0d9a-4afd-8bbc-c97873fece8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b9605d5-8e71-4bd2-898d-4487c6595a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3442, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True) # Find mew\n",
    "bndiff = hprebn - bnmeani # x- mew \n",
    "bndiff2 = bndiff**2  # (x - mew)**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n) # Variance, sigma squared\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability, bcuz vv high logits can cause .exp() to give inf rmb?\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693bc7c7-5355-4bcc-9782-9384ac5e6647",
   "metadata": {},
   "source": [
    "Bessel's correction : Unbiased estimate 1/(n-1).\n",
    "\n",
    "We learn in school that when we are learning from batches instead of the whole population we divded by n-1, since when learnign from batches, we almost always underestimate the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aa91900-d88e-4a34-b942-c1f226cfe435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
       "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb\n",
    "#Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27ffaa1-cbfc-45a7-bcdf-16dac7d5538d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs.shape\n",
    "# We are plucking out 8 from 1st row, 14 from 2nd row, and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c3ea943-bf28-4e32-be9e-b94b0878f6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.9245, -3.0769, -3.7317, -3.2031, -4.1305, -3.5683, -3.1179, -4.0072,\n",
       "        -3.1981, -4.3132, -3.1671, -1.6871, -2.7952, -3.0317, -3.0178, -3.1254,\n",
       "        -3.9029, -3.0216, -3.5290, -3.4031, -2.8970, -3.0021, -4.3013, -4.0711,\n",
       "        -3.4528, -2.8629, -3.0094, -3.8753, -2.7998, -3.4382, -3.2455, -3.1063],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[range(n), Yb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c27ff8c-cb48-4b99-a467-33d058f3e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explaining dlogprobs\n",
    "# loss = -1/3a + -1/3b + -1/3c\n",
    "# dloss/da = -1/3 , More generally, -1/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de644a3f-fb57-438f-80b3-f5d75354476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explaining dcounts_sum_inv\n",
    "# c = a * b, but with tensors:\n",
    "# a[3,3] * b[3,1] --->\n",
    "# a11*b1 a12*b1 a13*b1\n",
    "# a21*b2 a22*b2 a23*b2\n",
    "# a31*b3 a32*b3 a33*b3\n",
    "#c[3x3]\n",
    "\n",
    "#Finding gradient of b(dcounts_sum_inv) is a, but since b is used multiple times across each row, we have to find the sum of \n",
    "#gradients of b across each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0961a2b3-e137-4637-9246-4c2f94fe3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explaining dcounts \n",
    "# a11 a12 a13   ---> b1 (= a11 + a12 + a13)\n",
    "# a21 a22 a23   ---> b2 (= a21 + a22 + a23)\n",
    "# a31 a32 a33   ---> b3 (= a31 + a32 + a33)\n",
    "\n",
    "# any changes to any a element is correspondingly updated to its b element by a factor of 1. No \"powering up/weaking\" involved\n",
    "# so b's gradient is just routered to all a elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b728a65-4a89-48c4-8184-d35c30bf1ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explaining dlogit_maxes\n",
    "norm_logits.shape, logits.shape, logit_maxes.shape\n",
    "#similar to dcounts_sum_inv,\n",
    "\n",
    "# c11 c12 c13 = a11 a12 a13     b1\n",
    "# c21 c22 c23 = a21 a22 a23  -  b2\n",
    "# c31 c32 c33 = a31 a32 a33     b3\n",
    "\n",
    "#so e.g. c32 = a32 - b3 , the derivative of c to its corresponding elements : for a is 1, but b is -1 . So grad of c will flow\n",
    "# accordingly to a's and b's , but in addition to that since b is broadcasted, we have to do the sum as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15ef0c8f-c408-4c15-8841-92143c55f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explaining dlogits\n",
    "# logits.max(1) gives both positions and values of the max, logits.max(1).indices gives the positions \n",
    "# plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))\n",
    "# Then when we * dlogit_maxes, we route the gradient to only the [1]s\n",
    "# Note that the local derivative is just 1, hence we could use one_hot encoding too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0015a0-683c-45d8-9872-aac0d272ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explaining logits = h @ W2 + b2\n",
    "# Time stamp 46:15\n",
    "# Can use the hacky way of just looking at what shape tensor you need\n",
    "# Note that @ is not * , @ is dot product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013ff41-5bb3-4776-9a1f-c7ba6c40d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explaining dbndiff2\n",
    "# a11 a12\n",
    "# a21 a22\n",
    "# --->(sum along column gives) b1   b2, where:\n",
    "# b1 = 1/(n-1) * (a11 + a21)\n",
    "# b2 = 1/(n-1) * (a12 + a22)\n",
    "\n",
    "# The gradients of row vector b, has to be backpropagated along the respective COLUMNs of a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e60d4699-a93e-49fa-8668-1e1ff66dae41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "# --------------------\n",
    "# YOUR CODE HERE :)\n",
    "# --------------------\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs) # creates an array exactly in the shape of logprobs\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "\n",
    "dprobs = (1.0 / probs) * dlogprobs # d/dx(logx) = 1/x , and Chain Rule\n",
    "# From this you can see that if the answer character has low probability, dprobs increases, which increases lose, \"boosting their gradient\"\n",
    "cmp('probs', dprobs, probs)\n",
    "\n",
    "dcounts_sum_inv = (dprobs * counts).sum(1, keepdim=True) # keepdim so we get shape [32 , 1] instead of [32] only\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "# counts.shape, counts_sum_inv.shape # BEcareful, torch actually does 27 duplication horizontally to do multiplication here\n",
    "# So you need to sum along dimension 1 (horizontally)(basically for all the times that it is used)\n",
    "\n",
    "dcounts = counts_sum_inv * dprobs # counts is used twice in calculations! so we cant compare just yet\n",
    "dcounts_sum = -(1/counts_sum**2) * dcounts_sum_inv # d/dx(x**-1) = -1/x**-2 , and Chain Rule\n",
    "cmp('counts_sum', dcounts_sum, counts_sum) \n",
    "\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "# ones as operator was addition so gradient just flows as per norm\n",
    "cmp('counts', dcounts, counts)\n",
    "\n",
    "dnorm_logits = norm_logits.exp() * dcounts # d/dx(e**x) = e**x, and Chain Rule\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "cmp('logits', dlogits, logits)\n",
    "\n",
    "dh = dlogits @ W2.T # .T means transpose\n",
    "cmp('h', dh, h)\n",
    "\n",
    "dW2 = h.T @ dlogits\n",
    "cmp('W2', dW2, W2)\n",
    "\n",
    "db2 = dlogits.sum(0)\n",
    "cmp('b2', db2, b2)\n",
    "\n",
    "dhpreact = (1.0 - h**2) * dh # d/dx of tanh(x) is 1 - (tanh(x))**2\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "\n",
    "dbnraw = bngain * dhpreact\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "\n",
    "dbnvar_inv = (dbnraw * bndiff).sum(0, keepdim = True) # Rmb dim 0 : collapse(updown), dim 1: slap(leftright)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "\n",
    "dbndiff = bnvar_inv * dbnraw # bndiff i used twice (in 2 branches)\n",
    "\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar # [32,64] * [1,64], letting broadcasting help us\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "\n",
    "dbndiff += 2 * bndiff * dbndiff2 \n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "\n",
    "dbnmeani = -1 * dbndiff.sum(0, keepdim=True)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "\n",
    "dhprebn = dbndiff\n",
    "dhprebn += (1.0/n)*torch.ones_like(dhprebn) * dbnmeani # Similar to dbndiff2\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "\n",
    "dembcat = dhprebn @ W1.T\n",
    "cmp('embcat', dembcat, embcat)\n",
    "\n",
    "dW1 = embcat.T @ dhprebn\n",
    "cmp('W1', dW1, W1)\n",
    "\n",
    "db1 = dhprebn.sum(0)\n",
    "cmp('b1', db1, b1)\n",
    "\n",
    "demb = dembcat.view(emb.shape) # Just viewing it as the original shape\n",
    "cmp('emb', demb, emb)\n",
    "\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j] # iterate through all elements\n",
    "        dC[ix] += demb[k,j] # += because the same row from C could have been used many times\n",
    "        # demb[k,j] contains a row of 10 vectors!\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "957636b1-7bdb-48a4-8905-0f2b20345367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.344177722930908 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ccefa589-6aae-46f0-98fa-973d60389f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "#Shortening backward pass through differentiating the mathematical form of .cross_entropy\n",
    "\n",
    "# --------------------\n",
    "# YOUR CODE HERE :)\n",
    "# --------------------\n",
    "\n",
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1) # since after differentiating the gradient of the logit is itself after softmax(Pi)?\n",
    "dlogits[range(n), Yb] -= 1 # only difference is the correct ans is Pi - 1 \n",
    "dlogits /= n # Rmb that loss is the average loss occured from each example in the batch\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59cb7c4e-b1bb-4c06-a257-df495c98a02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c18f8da2-9907-461a-847a-303747bf2df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0665, 0.0911, 0.0185, 0.0504, 0.0180, 0.0770, 0.0276, 0.0362, 0.0198,\n",
       "        0.0295, 0.0366, 0.0361, 0.0392, 0.0304, 0.0359, 0.0127, 0.0096, 0.0212,\n",
       "        0.0164, 0.0573, 0.0456, 0.0218, 0.0293, 0.0685, 0.0574, 0.0260, 0.0215],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0bb27fd4-3c24-4db3-942e-2782d77fee1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0665,  0.0911,  0.0185,  0.0504,  0.0180,  0.0770,  0.0276,  0.0362,\n",
       "        -0.9802,  0.0295,  0.0366,  0.0361,  0.0392,  0.0304,  0.0359,  0.0127,\n",
       "         0.0096,  0.0212,  0.0164,  0.0573,  0.0456,  0.0218,  0.0293,  0.0685,\n",
       "         0.0574,  0.0260,  0.0215], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n\n",
    "# Note that the correct ans has -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8c50885-f659-4f28-9743-30cc43737232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3283e-10, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum() #(approximately 0)\n",
    "# This shows that the amount we pull up on probabilities is equal to the amount we pull down on the probabilities\n",
    "\n",
    "# For example, if our model is trained perfectly, where all wrong ans is 0, and correct ans prob is exactly 1, we will then -1 from \n",
    "# the correct char, and have a full row of 0 gradients. p.data += -lr * p.grad , so there is no update needed which is correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6b05c23-0480-4379-990a-176e0b3ab17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1694117e090>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')\n",
    "# Batch of 32 examples for vocab size of 27 chars\n",
    "# So what exactly is dlogits? (besides the fact that we know they are the derivative of logits)\n",
    "# We are pulling down the probabilities of wrong chars, and pulling up the probabilities of the correct char in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc537cf7-f580-43b5-bf60-3203c44b92ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# Note : hprebn : stands for hidden states for the pre batch normalization\n",
    "# hpreact : stands for hidden states pre activation\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9fc270c-9151-48f2-9f94-4becc227e72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "307c642f-503b-417b-ba1c-5b58abda8c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1aadd11-7d3c-498b-87ea-bf982dd69552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.7877\n",
      "  10000/ 200000: 2.2073\n",
      "  20000/ 200000: 2.4043\n",
      "  30000/ 200000: 2.4325\n",
      "  40000/ 200000: 1.9854\n",
      "  50000/ 200000: 2.3670\n",
      "  60000/ 200000: 2.3711\n",
      "  70000/ 200000: 2.0145\n",
      "  80000/ 200000: 2.4182\n",
      "  90000/ 200000: 2.1334\n",
      " 100000/ 200000: 1.9815\n",
      " 110000/ 200000: 2.3496\n",
      " 120000/ 200000: 2.0274\n",
      " 130000/ 200000: 2.4323\n",
      " 140000/ 200000: 2.3031\n",
      " 150000/ 200000: 2.2187\n",
      " 160000/ 200000: 1.9385\n",
      " 170000/ 200000: 1.8903\n",
      " 180000/ 200000: 2.0422\n",
      " 190000/ 200000: 1.9102\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f44d6c5-9af8-4127-b7d6-65fa915ef8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for checking your gradients\n",
    "# for p,g in zip(parameters, grads):\n",
    "#   cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "271f8bf9-f936-4db6-94d8-de17dec4fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19793058-ff4e-49df-9a73-1678e11ac54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.072087049484253\n",
      "val 2.108250617980957\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb915ce1-d914-4d4a-8f1f-42903905fe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mora.\n",
      "mayah.\n",
      "seel.\n",
      "ndheyah.\n",
      "reisantengraege.\n",
      "zered.\n",
      "elin.\n",
      "shi.\n",
      "jen.\n",
      "eden.\n",
      "estanaraelyn.\n",
      "malaia.\n",
      "noshubergiagriel.\n",
      "kindreelynn.\n",
      "novana.\n",
      "ububred.\n",
      "ryyah.\n",
      "fael.\n",
      "yuma.\n",
      "myston.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3923e59-7ab9-44e4-bc64-6a60af74b3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
